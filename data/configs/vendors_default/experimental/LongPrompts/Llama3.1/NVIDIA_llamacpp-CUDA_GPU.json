{
  "SystemConfig": {
    "Comment": "Llama 3.1 8B Instruct, llama-cpp CUDA, GPU, Long prompts, Experimental",
    "TempPath": "",
    "EPDependenciesConfigPath": ""
  },
  "Scenarios": [
    {
      "Name": "Llama3",
      "Models": [
        {
          "ModelName": "Llama 3.1 8B gguf-Q4_0",
          "FilePath": "https://client.mlcommons-storage.org/deps/1.0/scenario_files/llm/llama3/models/GGML/Llama-3.1-8B-Instruct-Q4_0.gguf",
          "TokenizerPath": "https://client.mlcommons-storage.org/deps/1.0/scenario_files/llm/llama3/models/GGML/tokenizer.zip"
        }
      ],
      "InputFilePath": [
        "https://client.mlcommons-storage.org/deps/1.0/scenario_files/llm/llama3/data/intermediate4k/booksum_4k.json",
        "https://client.mlcommons-storage.org/deps/1.0/scenario_files/llm/llama3/data/intermediate4k/downloader_cpp_4k.json",
        "https://client.mlcommons-storage.org/deps/1.0/scenario_files/llm/llama3/data/substantial8k/booksum_8k.json",
        "https://client.mlcommons-storage.org/deps/1.0/scenario_files/llm/llama3/data/substantial8k/gov_report_train_infrastructure.json"
      ],
      "AssetsPath": [],
      "ResultsVerificationFile": "https://client.mlcommons-storage.org/deps/1.0/scenario_files/llm/generation-greedy-results.json",
      "DataVerificationFile": "",
      "Iterations": 3,
      "Delay": 0,
      "ExecutionProviders": [
        {
          "Name": "CUDA",
          "Config": {
            "device_type": "GPU",
            "gpu_layers": 999,
            "fa": 1,
            "no_mmap": 1
          }
        }
      ]
    }
  ]
}